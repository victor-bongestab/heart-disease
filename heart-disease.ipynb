{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE SUPPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data extraction\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Default\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Data viz\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uci_heart_data():\n",
    "    '''\n",
    "        Downloads dataset from the UCI Repository: Heart Disease.\n",
    "\n",
    "        Parameters:\n",
    "            None.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame: heart disease dataset.\n",
    "    '''\n",
    "    heart_disease = fetch_ucirepo(name='Heart Disease')\n",
    "\n",
    "    df_features = heart_disease.data.features\n",
    "    df_target = heart_disease.data.targets\n",
    "    df_full = pd.concat([df_features, df_target], axis=1)\n",
    "    \n",
    "    return df_full\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 BUSINESS UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRISP for Data Science\n",
    "\n",
    "This is the methodology I use in my projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading crisp img\n",
    "img = Image.open('img/crisp.png')\n",
    "\n",
    "# Show\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we begin tackling the problem by understanding it.\n",
    "\n",
    "Objective of this study:\n",
    "    - Supporting the development of a heart disease prevention system!\n",
    "\n",
    "My job as a Data Scientist is to create a predictive model to identify patients more likely to develop heart diseases.\n",
    "\n",
    "\n",
    "Dataset available in the URL from UC Irvine (UCI) ML Repository: https://archive.ics.uci.edu/ml/datasets/heart+disease.\n",
    "It's made of 4 databases: Cleveland, Hungary, Switzerland, and the VA Long Beach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I don't have support from a medical team, my decisions are solely made out of my dataset limited interpretation.\n",
    "\n",
    "Below, we can see a table with the variables information summary, taken directly from the UCI ML Repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data_features img\n",
    "img = Image.open('img/dataset_variables.png')\n",
    "\n",
    "# Show\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Target feature also have this extra info:\n",
    "\n",
    "num: diagnosis of heart disease (angiographic disease status)\n",
    "        -- Value 0: < 50% diameter narrowing\n",
    "        -- Value 1: > 50% diameter narrowing\n",
    "        (in any major vessel: attributes 59 through 68 are vessels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have the Target feature, it's possible to use supervised models to predict whether or not new patients are prone to heart diseases.\n",
    "\n",
    "The next steps are Data Extraction and Data Cleaning. We can better understand the data he have by diving into it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 DATA EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the dataset from UCI.\n",
    "df1 = uci_heart_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we begin to understand how the dataset was built in more depth.\n",
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just taking a look at the dataframe.\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking dataframe size.\n",
    "print( 'Rows: {}'.format( df2.shape[0] ) )\n",
    "print( 'Cols: {}'.format( df2.shape[1] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying information about variables types and missing values.\n",
    "type_value_analysis = pd.concat(\n",
    "    [df2.dtypes, df2.isna().sum()], \n",
    "    axis=1, \n",
    "    keys=['Data Types', 'Missing Values'])\n",
    "print(type_value_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to understand the missing values.\n",
    "df2[(df2['ca'].isna()) | (df2['thal'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't have any other information that could help determine the missing values \n",
    "# for 'ca' (flouroscopy result) or 'thal' (whatever this is). \n",
    "# \n",
    "# The decision here is to drop them. It's just 2.3% of our dataset, we'll survive.\n",
    "df2 = df2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to take a look in the variables with data type float64, as the \n",
    "# int64 alreary have their values determined by the nature of its type.\n",
    "# \n",
    "# These are 'oldpeak', 'ca' and 'thal'. Let's check their values. \n",
    "# \n",
    "# P.S.: UCI Repository says that 'oldpeak' and 'ca' are integer and 'thal' \n",
    "# is categorical.\n",
    "unique_values_dict = {\n",
    "    'oldpeak': list(df2['oldpeak'].unique()),\n",
    "    'ca': list(df2['ca'].unique()),\n",
    "    'thal': list(df2['thal'].unique())\n",
    "}\n",
    "\n",
    "for i in unique_values_dict:\n",
    "    print('{}: {}'.format(i, unique_values_dict[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see, 'ca' and 'thal' can be stored as integer. But, contrary to \n",
    "# the UCI recommendation, 'oldpeak' is indeed float.\n",
    "variables_to_integer = ['ca', 'thal']\n",
    "\n",
    "for i in variables_to_integer:\n",
    "    df2[i] = df2[i].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Identifying Categorical and Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's display unique values for each variable. Then we can decide on\n",
    "# the nature of the data attributes.\n",
    "attributes = list(df2.columns)\n",
    "attributes_dict = {}\n",
    "\n",
    "for att in attributes:\n",
    "    attributes_dict[att] = list(df2[att].unique())\n",
    "\n",
    "for i, j in attributes_dict.items():\n",
    "    print('{}: {}'.format(i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The values for 'num' are not as expected from the data description from UCI.\n",
    "# As we should have only 0 or 1, for False and True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete list of attributes:\n",
    "attributes = list(df2.columns)\n",
    "\n",
    "# For the numerical attributes, we can identify:\n",
    "num_attributes = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "\n",
    "# And for the categorical ones, we have:\n",
    "cat_attributes = [att for att in attributes if att not in num_attributes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Adjusting Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we saw, 'num' values are not as expected. We can follow \n",
    "# with 0 as 0, but 1, 2, 3, 4 as 1. \n",
    "# If I'd take a guess, it may identify from which of the four\n",
    "# databases these positives come from.\n",
    "df2.loc[df2['num'] > 0, 'num'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Identifying Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting histogram to identify weird patterns.\n",
    "df2[num_attributes].hist(bins=20, figsize=(10, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting histogram to identify weird patterns.\n",
    "df2[cat_attributes].hist(bins=20, figsize=(10, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything looks fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's adventure time.\n",
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Descriptive Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Numerical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Central Tendency\n",
    "ct1 = pd.DataFrame( df3[num_attributes].apply( np.mean ) ).T\n",
    "ct2 = pd.DataFrame( df3[num_attributes].apply( np.median ) ).T\n",
    "\n",
    "# Dispersion - std, min, max, range, skew, kurtosis\n",
    "d1 = pd.DataFrame( df3[num_attributes].apply( np.std ) ).T\n",
    "d2 = pd.DataFrame( df3[num_attributes].apply( min ) ).T\n",
    "d3 = pd.DataFrame( df3[num_attributes].apply( max ) ).T\n",
    "d4 = pd.DataFrame( df3[num_attributes].apply( lambda x: x.max() - x.min() ) ).T\n",
    "d5 = pd.DataFrame( df3[num_attributes].apply( lambda x: x.skew() ) ).T\n",
    "d6 = pd.DataFrame( df3[num_attributes].apply( lambda x: x.kurtosis() ) ).T\n",
    "\n",
    "summary = pd.concat( [ d2, d3, d4, ct1, ct2, d1, d5, d6 ] ).T.reset_index()\n",
    "summary.columns = [ 'attributes', 'min', 'max', 'range', 'mean', 'median', 'std', 'skew', 'kurtosis' ]\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In general, we have distributions close to Normal, with attention\n",
    "# to 'chol' with high kurtosis, indicating a high peak around the mean value.\n",
    "# And 'oldpeak' with high positive skewness, showing its tendency to lower\n",
    "# values, and high kurtosis, also highlighting a great peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[num_attributes].hist( bins=80 );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see an accumulation of 'oldpeak' in point zero and\n",
    "# and looks closer to normal distribution when not considering zero.\n",
    "sns.histplot(df3.loc[df3['oldpeak'] > 0, 'oldpeak'], bins = 50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a figura\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plotar o KDE plot para df3['num'] == 0\n",
    "sns.kdeplot(df3.loc[df3['num'] == 0, 'oldpeak'], shade=True, color='dodgerblue', label='Healthy')\n",
    "\n",
    "# Plotar o KDE plot para df3['num'] == 1\n",
    "sns.kdeplot(df3.loc[df3['num'] == 1, 'oldpeak'], shade=True, color='darkred', label='Risk')\n",
    "\n",
    "# Adicionar título e legenda\n",
    "plt.title('Sobreposição de KDE Plots')\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that 'oldpeak' serves as a good indicator for heart health.\n",
    "# From that, we can generalize and see how the other variables behave too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for att in num_attributes:\n",
    "    # Criar a figura\n",
    "    plt.figure(figsize=(8, 3))\n",
    "\n",
    "    # Plotar o KDE plot para df3['num'] == 0\n",
    "    sns.kdeplot(df3.loc[df3['num'] == 0, att], shade=True, color='dodgerblue', label='Healthy')\n",
    "\n",
    "    # Plotar o KDE plot para df3['num'] == 1\n",
    "    sns.kdeplot(df3.loc[df3['num'] == 1, att], shade=True, color='darkred', label='Risk')\n",
    "\n",
    "    # Adicionar título e legenda\n",
    "    plt.title('Sobreposição de KDE Plots')\n",
    "    plt.legend()\n",
    "\n",
    "    # Mostrar o gráfico\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age: patients in risk tend to be older;\n",
    "#\n",
    "# trestbps: resting blood pressure doesn't seem different for healthy\n",
    "# and in risk patients;\n",
    "#\n",
    "# thalach: healthy patients can achieve higher maximum heart rate. As a\n",
    "# physicist, I can deduce that this can be caused by lower overall lower \n",
    "# pressure in healthy pacients vessels, as the heart would need more power \n",
    "# to reach higher rates as the pressure rises - gotta check with medical \n",
    "# team;\n",
    "#\n",
    "# oldpeak: healthy patients tends to not have or have lower divergence\n",
    "# in ST depression induced by exercise compared to rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Categorical Attributes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heart_disease",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
